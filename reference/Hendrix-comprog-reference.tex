% -*- compile-command: "pdflatex -shell-escape Hendrix-comprog-reference.tex" -*-

\documentclass[10pt]{book}

\usepackage[margin=1in]{geometry}
\usepackage{fancyhdr}

\pagestyle{fancy}

% \lhead{\leftmark}
% \rhead{\rightmark}

% \lfoot{Hendrix Programming Team Reference}
% \rfoot{\thepage}

% TODO: make fancy header with page number and section etc.

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{hyperref}
\usepackage{xcolor}

\hypersetup{
    colorlinks,
    linkcolor={green!50!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}
}

\usepackage{titlepic}
\usepackage{graphicx}
\graphicspath{{images/}}

\usepackage[newfloat]{minted}
\usepackage{etoolbox}
\usepackage{mdframed}
\usepackage{booktabs}
\usepackage{xspace}
\usepackage{pifont}
\usepackage{xparse}

\usepackage{algorithm, algorithmicx}
\usepackage[noend]{algpseudocode}

\usepackage{caption}
\DeclareCaptionLabelFormat{algnonumber}{Algorithm}
\captionsetup[algorithm]{labelformat=algnonumber}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Inline code

\NewDocumentCommand{\code}{O{}O{}m}{\inputminted[linenos=true,mathescape,firstline=#1,lastline=#2,autogobble]{java}{code/#3}}
\newcommand{\pycode}[1]{\inputminted[linenos=true,mathescape]{python}{code/#1}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Links

\newcommand*{\fulllink}[1]{\hyperref[{#1}]{\nameref*{#1}~(\S\ref*{#1}, page~\pageref*{#1})}}
\newcommand*{\link}[1]{\hyperref[{#1}]{(\S\ref*{#1}, page~\pageref*{#1})}}

\newcommand{\javalogo}{\includegraphics[height=0.9\baselineskip]{Java}}
\newcommand*{\javadoclink}[2]{\href{https://docs.oracle.com/javase/10/docs/api/java/#1/#2.html}{\texttt{#2}}}
\newcommand*{\javadoc}[2]{\javalogo\ \javadoclink{#1}{#2}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Kattis

\newcommand{\kattislogo}{\raisebox{-0.2em}{\includegraphics[height=0.9\baselineskip]{Kattis}}}

\newcommand{\kattis}[1]{%
  \begin{mdframed}
  \kattislogo
  \def\nextitem{\def\nextitem{, }}
  \renewcommand*{\do}[1]{\nextitem\kattislink{##1}}
  \docsvlist{#1}
  \end{mdframed}
}

\newcommand{\kattislink}[1]{\href{https://open.kattis.com/problems/#1}{\texttt{#1}}}

\newcommand{\inlinekattis}[1]{\kattislogo\ \kattislink{#1}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Todos

\newif\iftodos
\todostrue
\newcommand{\todo}[1]{\iftodos\textcolor{red}{[TODO: #1]}\fi}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Warning

\newenvironment{warning}
{\par\begin{mdframed}[linewidth=2pt,linecolor=red]%
    \begin{list}{}{\leftmargin=1cm
        \labelwidth=\leftmargin}\item[\Large\ding{43}]}
    {\end{list}\end{mdframed}\par}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Misc

\newcommand{\eg}{\emph{e.g.}\xspace}
\newcommand{\ie}{\emph{i.e.}\xspace}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\title{Hendrix Programming Team Reference}
\titlepic{\includegraphics[width=3in]{Hendrix-logo}}
\maketitle

\tableofcontents
\newpage

\chapter{Limits}

As a rule of thumb, you should assume about $10^8$ (= 100 million)
operations per second.  If you can think of a straightforward brute
force solution to a problem, you should check whether it is likely to
fit within the time limit; if so, go for it!  Some problems are
explicitly written to see if you will recognize this.  If a brute
force solution won't fit, the input size can help guide you to search
for the right algorithm running time.

Example: suppose a problem requires you to find the length of a
shortest path in a weighted graph.
\begin{itemize}
\item If the graph has $|V| = 400$ vertices, you should use
  Floyd-Warshall \link{sec:floydwarshall}: it is the easiest to code and takes $O(V^3)$ time
  which should be good enough.
\item If the graph has $|V| = 4000$ vertices, especially if it doesn't
  have all possible edges, you can use Dijkstra's algorithm
  \link{sec:dijkstra}, which is $O(E \log V)$.
\item If the graph has $|V| = 10^5$ vertices, you should look for some
  special property of the graph which allows you to solve the problem
  in $O(V)$ or $O(V \log V)$ time---for example, perhaps the graph is
  a tree \link{sec:graph-basics}, so you can run a BFS/DFS \link{sec:dfs}
  to find the unique path and then add up the weights.  An input size of
  $10^5$ is a common sign that you are expected to use an $O(n \lg n)$
  or $O(n)$ algorithm---it's big enough to make $O(n^2)$ too slow but
  not so big that the time to do I/O makes a big difference.
\end{itemize}

\begin{table*}[h]\centering
  \renewcommand{\arraystretch}{1.3}
  \begin{tabular}{@{}lll@{}}\toprule
    $n$ & Worst viable running time & Example \\
    \midrule
    $11$ & $O(n!)$ & Generating all permutations \link{sec:combinatorics} \\
    $25$ & $O(2^n)$ & Generating all subsets \link{chap:bittricks} \\
    $100$ & $O(n^4)$ & Some brute force algorithms \\
    $400$ & $O(n^3)$ & Floyd-Warshall \link{sec:floydwarshall} \\
    $10^4$ & $O(n^2)$ & Testing all pairs \\
    $10^6$ & $O(n \lg n)$ & BFS/DFS; sort+greedy \\
    \bottomrule
  \end{tabular}
\end{table*}

\kattis{bing, transportationplanning, dancerecital, prozor,
  rectanglesurrounding, weakvertices}

\begin{itemize}
\item $2^{10} = 1024 \approx 10^3$.
\item One \texttt{int} is 32 bits = 4 bytes. So \emph{e.g.} an array
  of $10^6$ \texttt{int}s requires $< 4$ MB---no big deal since the
  typical memory limit is $1$ GB.  Don't be afraid to make arrays with
  millions of elements!
\item \texttt{int} holds 32 bits; the largest \texttt{int} value is
  \verb|Integer.MAX_VALUE| $ = 2^{31} - 1$, a bit more than
  $2 \cdot 10^9$.
\item \texttt{long} holds 64 bits; the largest
  \texttt{long} value is \verb|Long.MAX_VALUE| $ = 2^{63} - 1$, a bit
  more than $9 \cdot 10^{18}$. To write literal long values you can
  add an \texttt{L} suffix, as in \texttt{long x = 1234567890123L;}.
\item If you need larger values, use \fulllink{sec:bigint} or just use
  Python~\link{chap:python}; see also \fulllink{sec:combinatorics}.
\end{itemize}

\kattis{different}

\chapter{Java Reference}

\section{Template}

\code{java/Template.java}

\section{Scanner}

\javadoc{util}{Scanner} is relatively slow but should usually be sufficient
for most purposes.  If the input or output is relatively large (> 1MB)
and you suspect the time taken to read or write it may be a hindrance,
you can use \fulllink{sec:fastio}.

\begin{warning}
  Be sure to read the warning in the comment below about calling
  \texttt{nextLine()} after \texttt{nextInt()} and the like!
\end{warning}

\code{java/ScannerExample.java}

\section{String/StringBuilder}

\kattis{battlesimulation, bing, connectthedots, itsasecret, shiritori,
suffixarrayreconstruction}

The \javadoc{lang}{String} type can be used in Java to represent
sequences of characters.  Some useful \texttt{String} methods include:
\begin{itemize}
\item concatenation (\texttt{+})
\item \texttt{substring(i)} yields the substring starting at index
  \texttt{i} up to the end of the string
\item \texttt{substring(i,j)} yields the substring starting at
  \texttt{i} (inclusive) and ending \emph{just before} \texttt{j}
  (same as Python slices).
\item \texttt{charAt(i)} yields the \texttt{char} at index \texttt{i}.
\item \texttt{toCharArray()} converts to a \texttt{char[]}, which can
  be convenient if you need to do a lot of indexing (\texttt{[i]}
  instead of \texttt{charAt(i)}
\item \texttt{split(String)} splits a string into a \texttt{String[]}
  of pieces between occurrences of the splitting string.
\item \texttt{endsWith(String)}, \texttt{startsWith(String)},
  \texttt{indexOf(String)}, and \texttt{replace(...)} can occasionally be useful.
\end{itemize}

\todo{Example of using \texttt{split}, \emph{e.g.} solution to
  \inlinekattis{sumoftheothers}.}

\texttt{String}s are immutable, which means in particular that
concatenation has to allocate an entirely new \texttt{String} and copy
both arguments.  Hence repeatedly appending individual characters to
the end of a \texttt{String} takes $O(n^2)$ time, since the entire
string must be copied with each append operation.  In this situation,
either pre-allocate a sufficiently large \texttt{char[]}, or use
the \javadoc{lang}{StringBuilder} class.

\todo{Example of using \texttt{StringBuilder}.}

\kattis{itsasecret}

\section{Arrays}

\kattis{falcondive,freefood,traveltheskies}

The basic syntax for creating a primitive array in Java is, for example,
\begin{minted}{java}
int[] array = new int[500];
\end{minted}

Some tips and tricks:
\begin{itemize}
\item Array indexing starts at 0; however, problems sometimes index
  things from $1 \dots n$.  In such a situation it is usually a good
  idea to simply create an array with one extra slot and leave index 0
  unused.  The alternative (fiddling with indices by subtracting and
  adding 1 in the right places) is quite error-prone.
\item You can initialize an entire array to a given value using
  \texttt{Arrays.fill(array, value)}.
\item If you only want to initialize part of an array, use
  \texttt{Arrays.fill(array, fromIndex, toIndex, value)} to fill the
  array from \texttt{fromIndex} (inclusive) up to \texttt{toIndex}
  (exclusive).
\item You can sort the contents of an array in-place using
  \href{https://docs.oracle.com/javase/10/docs/api/java/util/Arrays.html#sort(int\%5B\%5D)}{\texttt{Arrays.sort}};
  see \fulllink{sec:sorting}.
\item You can use \texttt{Arrays.binarySearch(array, key)} to look for
  \texttt{key} within a sorted \texttt{array}.  Read
  \href{https://docs.oracle.com/javase/10/docs/api/java/util/Arrays.html#binarySearch(int\%5B\%5D,int)}{the
    documentation} to make sure you understand how to interpret the
  return value.  See also \fulllink{sec:binary-search}.
\item Other methods from the \javadoc{util}{Arrays} class may also
  occasionally be useful.
\end{itemize}

\section{ArrayList}

\javadoc{util}{ArrayList} represents a standard dynamically-extensible
array, doubling the underlying storage when it runs out of space so
that appending takes $O(1)$ amortized time.  The \texttt{add},
\texttt{get}, \texttt{set}, \texttt{size}, and \texttt{isEmpty}
methods are useful, in addition to the ability to iterate over the
elements in order.  Avoid methods such as \texttt{contains},
\texttt{indexOf}, \texttt{remove}, and the version of \texttt{add}
that takes an index, all of which take linear time.  (If you want any
of these methods it's probably a sign that you ought to be using a
different data structure.)

If you need to store a list/array and you know in advance exactly how
much storage space you will need, then prefer using a primitive array
which has less overhead as well as more concise syntax.  On the other
hand, if you want to be able to dynamically extend a list by appending
new elements to the end, use \texttt{ArrayList}.  (If you want to be
able to dynamically extend a list on \emph{both} ends, use an
\texttt{ArrayDeque} \link{sec:queue}.)

\begin{minted}{java}
ArrayList<Integer> lst = new ArrayList<>();
lst.add(3); lst.add(19); lst.add(6);
System.out.println(lst.get(2));   // prints 6
lst.set(1, 12);                   // changes 19 to 12
int sum = 0;
for (Integer i: lst) {            // iterate through all items
    sum += i;
}
System.out.println(sum);          // prints 3 + 12 + 6 = 21
\end{minted}

\section{Stack}

\kattis{backspace, islands, pairingsocks, reservoir, restaurant, symmetricorder,
  throwns, zagrade}

\javadoc{util}{Stack} provides a generic stack implementation with
$O(1)$ operations.  Standard methods include \texttt{isEmpty},
\texttt{push}, \texttt{pop}, \texttt{peek}, and \texttt{size}.  The
code below shows a sample solution to \inlinekattis{backspace} using
\javadoc{util}{Stack} (and \javadoc{util}{StringBuilder}).

\code{java/backspace.java}

Stacks are often used in implementing DFS \link{sec:dfs} as well as
dealing with parentheses, or nesting more generally
(\inlinekattis{pairingsocks}, \inlinekattis{islands},
\inlinekattis{reservoir}).

\section{Queue/ArrayDeque}
\label{sec:queue}

\kattis{brexit, coconut, ferryloading4, integerlists, shuffling}

\javadoc{util}{Queue}, unlike \javadoc{util}{Stack}, is not a class
but an interface.  There are several classes implementing the
\texttt{Queue} interface, but the best in the context of competitive
programming is probably \javadoc{util}{ArrayDeque}, which in fact
implements a \emph{double-ended queue} or \emph{deque}, providing
$O(1)$ amortized addition and removal from both ends.

The \texttt{add} and \texttt{remove} methods implement enqueueing and
dequeueing.  To access both ends, use \texttt{addFirst},
\texttt{addLast}, \texttt{removeFirst}, and \texttt{removeLast}, all
of which run in $O(1)$ amortized time. (\texttt{add} is the same as
\texttt{addLast} and \texttt{remove} is the same as
\texttt{removeFirst}.)

Queues are very commonly used in implementing \fulllink{sec:bfs} and
in simulations of various sorts (for examples of the latter, see the
selection of problems above).

\todo{Sample code using \texttt{Queue}/\texttt{ArrayDeque}}

\section{Comparator}
\label{sec:comparator}

\todo{Constructing Comparators via lambda; constructing via things
  like \texttt{comparing}, \texttt{thenComparing}.
  \texttt{Collections.reverseOrder()}.  Use for sorting, PQs,
  TreeSet/Map.}

\section{PriorityQueue}
\label{sec:pq}

\kattis{bank, ferryloading3, guessthedatastructure, knigsoftheforest, vegetables}

A \javadoc{util}{PriorityQueue} allows adding new elements
(\texttt{add}) and removing the \textbf{minimum} element
(\texttt{remove}), both in $O(\lg n)$ time.  \texttt{peek} can also
be used to get the minimum in $O(1)$ without removing it.  Priority
queues are commonly used in Dijkstra's algorithm \link{sec:dijkstra},
event-based simulations (\inlinekattis{ferryloading3}), and generally
any situation where we need to do an ``online sort'', that is, we need
to get items in order from smallest to biggest, but more items may
continue to arrive/be generated as we go.

Methods you should \emph{not} use with \texttt{PriorityQueue} include
\texttt{remove(Object)} and \texttt{contains(Object)}, which take
linear time.

The default constructor makes an empty min-PQ.  If you want to use a
different ordering, there is another constructor which takes a
\javadoc{util}{Comparator}.
\begin{itemize}
\item For example, if you want a \textbf{max} priority queue, where
  \texttt{remove()} yields the largest element, write something like
  \begin{minted}{java}
    PriorityQueue<Integer> pq = new PriorityQueue<>(Collections.reverseOrder());
  \end{minted}
\item If you want some other ordering, you can also use a lambda to
  construct a \texttt{Comparator} on the fly, for example:
  \begin{minted}{java}
    PriorityQueue<Integer> pq = new PriorityQueue<>((a,b) -> dist[a] - dist[b]);
  \end{minted}
\end{itemize}

Traditional presentations of priority queues often have a
\emph{decrease key} operation which can decrease the priority of an
item (or an \emph{adjust key} operation which can arbitrarily change
the priority) and reestablish the data structure invariants in
$O(\lg n)$ time; this operation is used, for example, in implementing
Dijkstra's algorithm efficiently \link{sec:dijkstra}.  However, the
Java \texttt{PriorityQueue} class has no such method.  One workaround
is to simply call \texttt{remove} and then \texttt{add} so the item
gets re-added with the new priority.  However, \texttt{remove} takes
linear time, so this is not ideal, although in many cases it is still
good enough.  For those (relatively rare) cases when an $O(\lg n)$
decrease key operation is truly essential, see \fulllink{sec:adj-pq}.

\section{Set}

\todo{HashSet, TreeSet}

\section{Map}

\kattis{awkwardparty, administrativeproblems, snowflakes}

\todo{HashMap, TreeMap}
\todo{Iterating over keys, values, both (MapEntry)}
\todo{Note for purposes of programming contests, TreeMap and HashMap
  are basically interchangeable.  HashMap is faster in theory but a
  factor of $\lg n$ is not that much, and HashMap has its own
  overhead.  Much easier to use custom classes as keys in a TreeMap
  (just implement Comparable) than in a HashMap (implement hashCode
  and equals).}

\section{BigInteger} \label{sec:bigint}

\todo{Examples.  Useful methods, constructors (gcd, mod, base conversion!).}

\kattis{basicremains}

\section{Sorting}
\label{sec:sorting}

\todo{Basic template for implementing Comparable}
\todo{Arrays.sort, Collections.sort}
\todo{Sorting with a custom \texttt{Comparator}}
\todo{Include code for basic sorting implementations (in case it's
  useful to code them up explicitly so they can be enhanced with extra
  info): insertion sort, mergesort, quicksort)}

\section{BitSet} \label{sec:bitset}

\todo{Basic examples of BitSet use.}

\kattis{primesieve}

\section{Fast I/O} \label{sec:fastio}

Typically ACM ICPC problems are designed so \texttt{Scanner} and
\texttt{System.out.println} are fast enough to read and write the
required input and output within the time limits.  However, these are
relatively slow since they are unbuffered (every single read and write
happens immediately).  Occasionally it can be useful to have faster
I/O; indeed, a few problems on Kattis cannot be solved in Java without
using this.

\kattis{avoidland, cd}

\begin{warning}
  Be sure to call \texttt{flush()} at the end of your program
  or else some output might be lost!
\end{warning}

\code{java/Kattio.java}

% \todo{Add \texttt{getLine()} method}

\chapter{Python Reference} \label{chap:python}

Python's built-in support for arbitrary-size integers (using
\texttt{BigInteger} in Java is a pain!) and built-in dictionaries with
lightweight syntax make it attractive for certain kinds of problems.

\section{Template}

Below is a basic template showing how to read typical contest problem
input in Python:

\pycode{python/template.py}

\todo{Mention basic Python data structures such as set, deque, list methods}

\chapter{Data Structures}

\section{Bag}

\kattis{cookieselection}

A \emph{bag} is a collection of elements where order does not matter
(like a set) but multiplicity does matter, \ie there can be
duplicates.  Bags are not needed often but can occasionally be useful.
It is not too hard to build a bag as a map from values to integer
counts, but there are a few corner cases so it's worth copying a
well-tested implementation instead of writing one from scratch.

The implementation below is based on a \javadoc{util}{TreeMap}, and
hence supports operations like \texttt{first()} and \texttt{last()}.
If desired one could easily change the \texttt{TreeMap} to a
\texttt{HashMap} and remove the methods which are no longer supported.

\code{data-structures/TreeBag.java}

\section{Union-find}

\kattis{forestfires, kastenlauf, ladice, numbersetseasy, unionfind, virtualfriends,
  wheresmyinternet}

A union-find structure can be used to keep track of a collection of
disjoint sets, with the ability to quickly test whether two items are
in the same set, and to quickly union two given sets into one.  It is
used in Kruskal's Minimum Spanning Tree algorithm \link{sec:kruskal},
and can also be useful on its own (see the above Kattis problems for
examples).  \texttt{find} and \texttt{union} both take essentially
constant amortized time.

\code{data-structures/UnionFind.java}

The above code can easily be enhanced to keep track of the number of
sets (initialize to \texttt{n}; subtract one every time \texttt{union}
hits the \texttt{ru != rv} case), or to keep track of the actual size
of each set instead of just the rank/height (keep a size for each
index; initialize all to 1; add sizes appropriately when doing
\texttt{union}).

\section{Tries}

\kattis{boggle, heritage, herkabe, phonelist}

The code below is a very simple implementation of a trie---there are
many other methods that could be added, and it is not very efficient
since it repeatedly uses the $O(n)$ \texttt{substring} operation as it
recurses down the trie, but it is sufficient for some problems.

\code{data-structures/Trie.java}

\section{Adjustable priority queue}
\label{sec:adj-pq}

\kattis{flowerytrails}

As discussed in \fulllink{sec:pq}, Java's \texttt{PriorityQueue} class
has no way to efficiently alter the priority of an item already stored
in the queue; simply removing and re-adding the item does the trick
but takes $O(n)$ time.  The efficiency of this operation really does
make a difference in the asymptotic performance of Dijkstra's
algorithm \link{sec:dijkstra}, and occasionally it really needs to be
$O(\lg n)$ in order to meet the time limits (\emph{e.g.}
\inlinekattis{flowerytrails}). A suitable implementation of a priority
queue with $O(\lg n)$ priority adjustment is shown below.  The key
idea is to keep a hash table on the side which can be used to quickly
find the index of any item stored in the priority queue; of course,
the hash table has to be kept suitably updated whenever items are
shuffled in the heap.  The \texttt{adjust(e)} method is used to inform
the priority queue that the priority of item \texttt{e} has changed,
so that the queue has an opportunity to move the item if necessary to
reestablish the heap invariants.

\code{data-structures/AdjustablePQ.java}

\section{Segment trees and Fenwick trees}

See \fulllink{sec:range-queries}.

\chapter{Search}

\section{Complete search}

\kattis{bing, classpicture, coloring, dancerecital, lektira, freefood, gepetto,
  kastenlauf, mjehuric, paintings, prozor, rectanglesurrounding,
  reducedidnumbers, reseto, sheldon, shuffling,
  weakvertices, wheels, transportationplanning}

See CP3 for a fuller discussion of complete search, aka brute force,
and a list of relevant techniques (nested loops, recursive
backtracking, \emph{etc.}).  Just remember that there's no need to
code anything more sophisticated if a back-of-the-envelope analysis
shows that a simple complete search will finish under the time
limit. (Although some kinds of complete search can themselves be
rather sophisticated.  For example, see \fulllink{chap:bittricks}.
Some of the above problems are much harder than others!)

Sometimes complete search isn't in and of itself the full solution to
a problem, but the problem is set up so that a subpart can be done via
complete search, to keep the solution complexity from getting out of
hand and allowing you to focus your efforts on the more
``interesting'' part of the problem.

\section{Binary search}
\label{sec:binary-search}

\kattis{bottles, cheese, guess, insert, speed, suspensionbridges, tetration}

\todo{Binary search on an array; binary search on unbounded function
  on the integers; binary search on real interval}
\todo{Point out \texttt{Arrays.binarySearch}}

\todo{When searching over the integers, make sure you're very explicit
  about whether the lo and hi bounds are included or
  excluded. Probably easiest to include.}

\section{Ternary search}

\kattis{brocard, euclideantsp, infiniteslides, janitortroubles}

\todo{Write about ternary search.}

\chapter{Graphs}

\section{Graph basics} \label{sec:graph-basics}

\todo{Directed, undirected, weighted, unweighted, self loops, multiple edges}
\todo{characterization of trees}
\todo{New virtual source/sink node trick}

\kattis{chopwood}

\section{Graph representation}

\todo{Adjacency matrix, adjacency maps.  Edge objects. Implicit
  graphs.}

Figure~\ref{fig:horrorlist} has a sample solution for
\inlinekattis{horrorlist} which builds an adjacency map
representation of an undirected graph.

\todo{State space search with complex states: make a class, implement
  Comparable, use TreeMap}

\section{BFS}
\label{sec:bfs}

\kattis{brexit, collapse, grapevine, horrorlist, mazemakers}

Breadth-first search (BFS) can be used to find single-source shortest
paths (\emph{i.e.} shortest paths from a particular starting vertex to
all other vertices) in an unweighted graph. BFS comes up often in many
different guises, so it's worth being very familiar with BFS and its
variants. Below is pseudocode showing a generic BFS implementation.
Important invariants:
\begin{itemize}
\item Every vertex in $Q$ has already been marked visited. (This is
  important since it prevents vertices from being added to $Q$
  multiple times.)
\item $Q$ only contains vertices from at most two (consecutive) levels
  at a time.
\end{itemize}

\begin{center}
\begin{minipage}{0.8\textwidth}
\begin{algorithm}[H]
  \begin{algorithmic}[1]
\State $s \gets$ starting vertex
\State Mark $s$ visited
\State $Q \gets$ new queue containing only $s$
\State $\mathit{level}[s] \gets 0$
\While{$Q$ not empty}
  \State $u \gets Q.\mathit{remove}$
  \For{each neighbor $v$ of $u$}
    \If{$v$ is not visited}
      \State $\mathit{level}[v] \gets \mathit{level}[u] + 1$ \Comment{Optionally mark level}
      \State Add $v$ to $Q$
      \State Mark $v$ visited
      \State $\mathit{parent}[v] \gets u$ \Comment{Optionally record parent}
    \EndIf
  \EndFor
\EndWhile
  \end{algorithmic}
\caption{BFS}
\end{algorithm}
\end{minipage}
\end{center}

Some options/variants:
\begin{itemize}
\item The $\mathit{level}$ array shown above is optional, and can be
  omitted if not needed.  Sometimes it makes sense to have the
  $\mathit{level}$ array do double-duty to also track visited vertices:
  if the $\mathit{level}$ of every vertex is initialized to some
  nonsensical value such as $-1$ or $\infty$, then a vertex is visited
  iff its $\mathit{level}$ is not equal to the initial value.

  Figure~\ref{fig:horrorlist} shows a sample solution for
  \inlinekattis{horrorlist}, exhibiting a BFS with level labelling.
\item The parent map is also optional, and can be used to reconstruct
  an actual shortest path from $s$ to any vertex, by starting with the
  end vertex and iteratively following parents backwards until
  reaching $s$.
\item If you want to compute shortest paths from \emph{any} of a set
  of starting vertices, simply replace the initialization of $s$ with
  the desired set (\emph{i.e.} mark them all visited, add them all to
  $Q$, and set their $\mathit{level}$ to $0$ before starting the loop;
  the loop itself does not change).
\item Replacing $Q$ with a stack results in a depth-first rather than
  breadth-first search (although often it makes more sense to
  implement a DFS recursively; see \link{sec:dfs}).
\end{itemize}

\begin{figure}
  \small
  \code{graph/horrorList.java}
  \caption{Sample solution for \texttt{horrorlist} (Adjacency set
    representation; BFS with level labelling)}  \label{fig:horrorlist}
\end{figure}

\todo{Applications of BFS: identify reachable vertices; identify
  (weakly) connected components; identify bipartite graphs/odd cycles
  (detect cross-edges with map of level sets)}

\section{DFS, SCCs, topological sorting} \label{sec:dfs}

\todo{Code for DFS, start/finish labelling, top sorting, Tarjan's SCC algorithm}

\section{Single-source shortest paths (Dijkstra)} \label{sec:dijkstra}

\section{All-pairs shortest paths (Floyd-Warshall)} \label{sec:floydwarshall}

\section{Min spanning trees (Kruskal)} \label{sec:kruskal}

\kattis{drivingrange, islandhopping, jurassicjigsaw, lostmap, minspantree, treehouses}

\section{Max flow}

A \emph{flow network} is a directed, weighted graph where the edge
weights (typically integers) are thought of as representing
\emph{capacities} (\eg imagine pipes of varying sizes).  The \emph{max
  flow problem} is to determine, given a flow network, the maximum
possible amount of \emph{flow} which can move through the network
between given source and sink vertices, subject to the constraints
that the flow on any edge is no greater than the capacity, and the sum
of incoming flows equals outgoing flows at every vertex other than the
source or sink.  Flow networks can be used to model a wide variety of
problems.

\todo{Enumerate a few problem types: item assignment; max bipartite
  matching; min cut}

\todo{choose directed/undirected edges carefully!}

\todo{Requires vertices $0 \dots n-1$: either carefully keep track of
  which numbers are for which vertices, or use lookup tables}

\kattis{copsandrobbers,escapeplan,gopher2,guardianofdecency,marblestree,maxflow,mincut,paintball,waif}

Dinitz' Algorithm is probably the best all-around algorithm to use for
solving max flow problems in competitive programming.  It takes
$O(V^2 E)$ in theory (although is often much faster in practice).  In
the special case where we are modelling a bipartite matching problem,
Dinitz' Algorithm reduces to the Hopcroft-Karp algorithm which runs in
$O(E \sqrt{V})$.

\code{flow/Dinitz.java}

\todo{Include a sample solution using a flow network}

\todo{Variants: Multiple sources/sinks? Use trick of adding a new
  source/sink with infinite capacity edges. Vertex capacities?
  Turn each vertex into a new edge.}

\chapter{Dynamic Programming}

\todo{knapsack, longest common subsequence}
\todo{longest increasing subsequence ($O(n^2)$ and $O(n \lg n)$, see \url{https://stackoverflow.com/questions/2631726/how-to-determine-the-longest-increasing-subsequence-using-dynamic-programming})}

\chapter{Strings}

\section{Z-algorithm}

\section{Suffix arrays}

\chapter{Mathematics}

\section{GCD/Euclidean Algorithm} \label{sec:euclid}

The \emph{Euclidean algorithm} can be used to compute the greatest
common divisor of two \textbf{nonnegative} integers. (If you need it
to work for negative numbers as well, just take absolute values
first.)  It runs in logarithmic time.  The \emph{extended Euclidean
  algorithm} not only finds the GCD $g$ of $a$ and $b$, but also finds
integers $x$ and $y$ such that $ax + by = g$.

\kattis{fairwarning, jughard, kutevi, candydistribution}

\code{math/GCD.java}

\section{Rational numbers}

Occasional problems may require dealing with explicit rational values
rather than using floating-point approximations.  If a problem
involves non-integer values but requires being able to test values for
equality \emph{exactly}, then likely rational numbers are required.
The below code for a \texttt{Rational} class is not difficult but it's nice
to have it as a reference. Of course in a real contest situation you
may not need all the methods.

\kattis{jointattack,prosjek,prsteni,rationalarithmetic,wheels,zipfsong}
\newpage

\code{math/Rational.java}

\section{Modular arithmetic}

\kattis{crackingrsa,modulararithmetic,pseudoprime,reducedidnumbers}

\begin{warning}
  Java's mod operator \texttt{\%} behaves strangely on negative
  numbers. In many other languages (\eg Python, Haskell) \texttt{a \%
    b} always returns a result between $0$ and $b-1$; however, in Java
  (as in C/C++), if \texttt{a} is negative then \texttt{a \% b} will
  also be negative.  Try adding \texttt{b} first if you need a
  nonnegative result.
\end{warning}

For example, suppose \texttt{i} is an index into an array of length
\texttt{n} and you need to shift by an offset \texttt{o}, wrapping
around in case the index goes off the end of the array.  The obvious
way to write this would be

\begin{minted}{java}
i = (i + o) % n;
\end{minted}

however, this is \textbf{incorrect if \texttt{o} could be negative!}
If we assume that \texttt{o} will never be larger in absolute value
than \texttt{n}, then we could write this correctly as

\begin{minted}{java}
i = (i + o + n) % n;
\end{minted}

If \texttt{o} could be arbitrarily large then we could write

\begin{minted}{java}
i = (((i + o) % n) + n) % n;
\end{minted}

(the first mod operation reduces it to lie between $-n \dots n$;
adding $n$ ensures it is positive; and the final mod reduces it to the
range $[0,n)$).

\textbf{Modular exponentiation and modular inverses}. Sometimes one
needs to compute the modular exponentiation $b^e \bmod m$ for some
base $b$, exponent $e$, and modulus $m$.  Using repeated squaring, it
is possible to do this efficiently even for very large exponents $e$.
Relatedly, if $b$ is relatively prime to $m$, it is possible to
compute $b^{-1} \bmod m$, the \emph{modular inverse} of $b$, that is,
the unique number $0 < b' < m$ such that $bb' \equiv 1 \pmod m$.

In Java, probably the easiest way to compute these is using the
\texttt{modPow} method from the \texttt{BigInteger} class
\link{sec:bigint}.  If \texttt{b}, \texttt{e}, and \texttt{m} are
\texttt{BigIntegers}, then \texttt{b.modPow(e, m)} is a
\texttt{BigInteger} that represents $b^e \bmod m$.  The exponent
\texttt{e} can also be negative; in particular, if \texttt{e} is $-1$
then \texttt{b.modPow(e,m)} will compute the inverse of
\texttt{b} modulo \texttt{m}.

It is also useful to know how to compute modular exponentiation and
inverses manually, in case you need some sort of variant version, or
if \texttt{BigInteger} is not fast enough.

\textbf{Modular exponentiation} can be computed by repeated squaring.
The basic idea is to compute $b^e$ by splitting up $e$ into a sum of
powers of two (according to its binary expansion), raising $b$ to each
power of two and taking the product.  This can be done efficiently
since we can get from $b^{2^k}$ to $b^{2^{k+1}}$ just by squaring.

  \begin{warning}
    Even if you need the answer modulo an \texttt{int} value such
    as $10^9 + 7$, it is important to use \texttt{long} in the method
    below: the product of two \texttt{int} values does not necessarily
    fit in an \texttt{int}, even if the very next step will reduce it
    modulo $m$ back into the range of an \texttt{int}.
  \end{warning}

\code[2][10]{math/ModExp.java}

Note this correctly computes $0^0 = 1$.  It would be possible to add a
special case for when $b = 0$ and $e \neq 1$, to avoid multiplying $0$
by itself a bunch of times, but it's hardly worth it.

\textbf{Modular inverses} can be computed using the extended Euclidean
algorithm \link{sec:euclid}.  In particular, suppose $a$ and $b$ are
relatively prime, that is, their GCD is $1$.  In that case the
\texttt{egcd} algorithm will compute numbers $x$ and $y$ such that
$ax + by = 1$.  Taking this equation $(\bmod b)$ yields \[ ax + by
  \equiv ax \equiv 1 \pmod b, \] and so $x$ is the modular inverse of
$a$ modulo $b$ (in practice one may want to reduce $x \bmod b$ so $x$
is between $0$ and $b-1$).

Alternatively, for a prime $p$, Fermat's Little Theorem says that
\[ a^{p-1} \equiv 1 \pmod p \] and hence $a^{p-2}$ is the modular
inverse of $a$ modulo $p$, which can be computed using modular
exponentiation.

\section{Primes and factorization}

Methods for primality testing and prime factorization that may show up
in a contest can be put in two main classes.  First, methods based on
\emph{trial division} are relatively simple to code and work well for
testing just one or a few numbers.  \emph{Sieve} based methods
construct a whole table of primes or factors all at once, and are
often more efficient when many numbers need to be factored or tested
for primality.

\subsection{Trial division}

\kattis{almostperfect,candydivision,crypto,enlarginghashtables,flowergarden,goldbach2,happyprime,iks,listgame,olderbrother,pascal,primalrepresentation}

To test whether a single number is prime, you can use the following
function which performs (somewhat optimized) trial division.  Note
that although there are faster primality testing methods (\eg
Miller-Rabin, Baille-PSW), it is highly unlikely that a contest would
ever require anything more sophisticated than divisibility testing:
Miller-Rabin is not hard to code but it is probabilistic, so a program
using it may give different results on subsequent runs, hardly
suitable for a competitive programming environment; Baille-PSW is
known to be deterministic for numbers up to $2^{64}$, but is much more
complex to code.

Note that \texttt{isPrime} has runtime $O(\sqrt n)$ and is hence
appropriate for numbers up to the maximum size of an \texttt{int}
($\approx 2 \cdot 10^9$); running it on inputs up to the maximum size
of a \texttt{long} is likely to be too slow.

\code[2][10]{math/IsPrime.java}

The following method takes $O(\sqrt n)$ to factor a number into its
prime factorization, also using trial division.  The returned prime
factors will be sorted from smallest to biggest.

\code[4][18]{math/Factor.java}

\subsection{Sieving}

\kattis{industrialspy,nonprimefactors,primereduction,primesieve,reseto}

The term \emph{sieve} comes from the ancient \emph{Sieve of
  Eratosthenes}, a very effective method for generating all the primes
up to a certain bound.  The basic idea is to make a table of all the
numbers from $1$ up to some upper bound $n$ and iterate through the
table. Each time we discover a prime $p$ we ``cross out'' all the
multiples of $p$ in the table; we know a number is prime if it hasn't
yet been crossed out by the time we get to.  This takes time
$O(n \log \log n)$ (essentially linear time) to construct a table for
$1 \dots n$.  The code below uses a \texttt{BitSet} \link{sec:bitset},
which uses less memory than an array of \texttt{boolean}s. Constructing
a \texttt{PrimeSieve} of size $10^8$ should take about a second and
use only about 12 MB of memory; constructing smaller prime sieves
should be quite fast.  Even a \texttt{PrimeSieve} of size
\texttt{Integer.MAX\_VALUE}, \ie $\approx 2 \cdot 10^9$, will fit
quite easily in memory, although constructing it will probably take
too long for most contest problems.  (However, there may be occasional
problems that require building a sieve of this size in order to
precompute some data offline---\ie writing a program that runs for a
few minutes in order to precompute some kind of set or lookup table to
be included in the submitted solution.)

\code{math/PrimeSieve.java}

Instead of simply storing a boolean indicating whether each number is
prime or not, we could also store the smallest prime factor.  We can
still use this to test whether a given number is prime, by checking
whether \texttt{smallest[n] == n}.  But we can also use it to quickly
factor any composite \texttt{n}: simply divide \texttt{n} by
\texttt{smallest[n]} and repeat. We can construct the smallest factor
array using a sieving method similar to \texttt{PrimeSieve}.  The
tradeoff is that this uses much more memory: instead of one bit per
number, we use an entire \texttt{int}, that is, 32 bits.  A
\texttt{FactorSieve} of size $10^8$ will take up around 380 MB.

The \texttt{FactorSieve} class below includes a trivial
\texttt{isPrime} method as well as a \texttt{factor} method, which is
carefully written to work even for \texttt{int} values which are
bigger than the lookup table.

\code{math/FactorSieve.java}

\section{Divisors and Euler's Totient Function}

\kattis{farey,relatives}

\todo{Number of divisors.  Euler's $\varphi$ function: computing
  directly and by sieving.}

\section{Factorial} \label{sec:factorial}

\kattis{eulersnumber, factstone, howmanydigits, lastfactorialdigit,
  inversefactorial, loworderzeros}

\todo{Computing factorials; size using logs, etc}

\section{Combinatorics} \label{sec:combinatorics}

\kattis{anagramcounting, nine, secretsanta, kingscolors, howmanyzeros}

\todo{Basic principles of combinatorics.  Code for computing binomial
  coefficients. Multinomial coefficients.}

\todo{mod $10^9 + 7$.}

\begin{warning}
  Remember to use \texttt{long} if you need an answer
  $\bmod (10^9 + 7)$ (which would fit in an \texttt{int}) but
  computing the answer requires \emph{multiplying} $\bmod (10^9 + 7)$.
\end{warning}

\todo{Heap's Algorithm for generating all permutations; next
  permutation.  See Bit Tricks for generating all subsets.}

\todo{PIE?}

\chapter{Bit Tricks} \label{chap:bittricks}

\kattis{bits, classpicture, flipfive, gepetto, hypercube, mazemakers,
  pagelayout, pebblesolitaire, satisfiability, turningtrominos}

\texttt{int} values are represented as a sequence of 32 bits;
\texttt{long} values are 64 bits.  Sometimes it is useful to think
about/work with such values directly as a sequence of bits rather than
as a number. We typically think of the bits as indexed from $0$
starting at the rightmost (least significant) bit.  For example,
\[ \arraycolsep=1pt
  974_{10} =
  \begin{array}{cccccccccc}
    1&1&1&1&0&0&1&1&1&0 \\
      \scriptscriptstyle 9
     &\scriptscriptstyle 8
     &\scriptscriptstyle 7
     &\scriptscriptstyle 6
     &\scriptscriptstyle 5
     &\scriptscriptstyle 4
     &\scriptscriptstyle 3
     &\scriptscriptstyle 2
     &\scriptscriptstyle 1
     &\scriptscriptstyle 0
  \end{array} \]
In general, a $1$ bit at index $i$ has value $2^i$.

One frequently useful point of view is to think of a value of type
\texttt{int}/\texttt{long} as representing a particular subset of a
given set of up to 32/64 items.  The bit at index $i$ indicates
whether item $i$ is included in the subset or not.

Java has built-in operators to manipulate values at the bit level:
\begin{itemize}
\item \texttt{\&} represents bitwise logical AND.  That is, the
  index-$i$ bit of the result is the logical AND of the index-$i$ bits
  of the inputs; each bit index is considered separately.  It is often
  useful to think of \texttt{\&} as a ``masking'' operation: given
  values \texttt{v} and \texttt{mask}, evaluating \texttt{v \& mask}
  will only ``let through'' the bits of \texttt{v} which correspond to
  $1$ bits in \texttt{mask}; all other bits will be ``turned off''.
  For example, if you want to extract only the last three bits of a
  value \texttt{v}, you can compute \texttt{v \& 7} (since bitwise AND
  with $7 = 111_2$ will turn off all bits except the last three).

  If values are thought of as representing subsets, then \texttt{\&}
  corresponds to set intersection.
\item \texttt{|} represents bitwise logical OR.  This can be used to
  ``turn on'' certain bits: \texttt{v \& on} will result in a value
  which is the same as \texttt{v} except that the bits which are set
  to $1$ in \texttt{on} will be turned on.

  If values are thought of as representing subsets, then \texttt{|}
  corresponds to set union.
\item \verb|^| represents bitwise logical XOR.  This can be used to
  ``toggle'' bits: \verb|v ^ toggle| will result in a value which is
  the same as \texttt{v} except that the bits in positions
  corresponding to the $1$ bits in \texttt{toggle} have been flipped.

  If values are thought of as representing subsets, then \verb|^|
  corresponds to symmetric difference: \verb|a ^ b| represents the set
  of elements which are in \verb|a| or \verb|b| but not both.
\item \verb|n >> k| shifts $n$ right by $k$ bits, chopping off the
  rightmost $k$ bits.  This corresponds to (integer) division by
  $2^k$.  \verb|n << k| shifts $n$ left by $k$ bits, adding $k$ zeros
  on the right; this corresponds to multiplying by $2^k$.

  Note that right shifting uses something called \emph{sign extension}
  so that it fills in bits on the left according to whatever the
  leftmost bit was initially: a value starting with a zero bit
  (\emph{i.e.} a positive value) will have zeros filled in on the
  left, but a (negative) value beginning with a one bit will have ones
  filled in on the left.  If you don't want this (it rarely matters!)
  you can use \verb|n >>> k| which does a right shift by $k$ bits
  \emph{without} sign extension, that is, it always fills in zero bits
  on the left regardless of the initial bit of $n$.
\end{itemize}

\subsection*{Bit strings for states}

\todo{Using bitstrings to compactly represent sets/states/adjacent
  neighbors.  Building a set, iterating through all subsets with
  counter.}

\todo{LSB, LSZ, MSB, pop count, iterating through sub-subsets}

\todo{BitSet instead of array of booleans.}

\chapter{Geometry} \label{chap:geometry}

\kattis{alldifferentdirections, convexpolygonarea, cookiecutter,
  countingtriangles, cranes, glyphrecognition, hittingtargets,
  hurricanedanger, jabuke, polygonarea, rafting}

\todo{Keep building above list---grep for geom.  Next to look at is robotprotection.}

\todo{Points, vectors, angles.  Degrees/radians. \texttt{atan2}. Dot
  product. Rotation. Vector magnitude, norm (squared), normalize.
  Perpendicular (generate, test).}  \todo{Cross product in 2D. Signed
  area (parallelogram, triangle, Heron's formula), polygon area,
  right/left turn, inside/outside testing.}  \todo{Lines/rays (point +
  vector).  Line intersection. Segment intersection. Closest point on
  a line/segment. Point/line distance.}
% -- Distance from point p to line defined by p1, p2 is absolute value
% -- of parallelogram area defined by p, p1, p2 divided by distance
% -- between p1, p2.  Proof: rearrange triangle area formula A = bh/2 to
% -- solve for h.
\todo{Convex hull.}

\chapter{Miscellaneous}

\section{2D grids}

2D grids/arrays (of characters, numbers, booleans\dots) are a popular
feature of many competitive programming problems.

\begin{itemize}
\item In many cases the grid should be thought of as a graph where
  each cell is a vertex which is connected by edges to its neighbors.
  Note that in these cases one rarely wants to explicitly construct
  a different representation of the graph, but simply use the grid
  itself as an (implicit) graph representation.
\item It is often useful to be able to assign a unique number to each
  cell in the grid, so we can store ID numbers of cells in data
  structures rather than making some class to represent a pair of a
  row and column index.  The easiest method is to number the first row
  from $0$ to $C-1$ (where $C$ is the number of columns), then the
  second row $C$ to $2C-1$, and so on.

  \begin{tabular}{|c|c|c|c|c|}
    \hline
    $0$ & $1$ & $2$ & $\dots$ & $C-1$ \\
    \hline
    $C$ & $C+1$ & $C+2$ & $\dots$ & $2C-1$ \\
    \hline
    $2C$ & $2C+1$ & $2C+2$ & $\dots$ & $3C-1$ \\
    \hline
    $\vdots$ & $\vdots$ & $\vdots$ & $\ddots$ & $\vdots$ \\
    \hline
    $(R-1)C$ & $(R-1)C+1$ & $(R-1)C+2$ & $\dots$ & $RC-1$ \\
    \hline
  \end{tabular}

\item Using this scheme, to convert between $(r,c)$ pairs and ID
  numbers $n$, one can use the formulas
  \[ (r,c) \mapsto r \cdot C + c \qquad n \mapsto (n / C, n \% C) \]

\item To list the four neighbors of a given cell $(r,c)$ to the north,
  east, south, and west, one can of course simply list the four cases
  manually, but sometimes this is tedious and error-prone, especially
  if there is a lot of code to handle each neighbor that needs to be
  copied four times.

  Instead, one can use the following template. The idea is that
  $(dr, dc)$ specifies the \emph{offset} from the current cell $(r,c)$
  to one of its neighbors; each time through the loop we rotate it
  counterclockwise by $1/4$ turn using the mapping
  $(dr,dc) \mapsto (-dc,dr)$ (see \fulllink{chap:geometry}).

  \code{grid/Neighbors.java}
\end{itemize}

\section{Range queries} \label{sec:range-queries}

Suppose we have a $1$-indexed array $A[1 \dots n]$ containing some
values, and there is some operation $\oplus$ which takes two values
and combines them to produce a new value.  Given indices $i$ and $j$,
we want to quickly find the value that results from combining all the
values in the range $A[i \dots j]$, \ie $A[i] \oplus A[i+1] \oplus
\dots \oplus A[j]$.

For example, $A$ could be an array of integers, and $\oplus$ could be
$\max$, that is, we want to find the maximum value in the range
$A[i \dots j]$.  Likewise $\oplus$ could be sum, or product, or GCD.
Or $A$ could be an array of booleans, and we want to find the AND, OR,
or XOR of the range $A[i \dots j]$.

\begin{itemize}
\item For this to make sense, the combining operation must typically
  be \emph{associative}, \ie $a \oplus (b \oplus c) = (a \oplus b) \oplus
  c$.  (This is called a \emph{semigroup}.)
\item Sometimes there is also an inverse operation $\ominus$ which
  ``cancels out'' the effects of the combining operation, that is, $(a
  \oplus b) \ominus b = a$ (this is called a \emph{group}).  For
  example, subtraction cancels out addition. On the other hand, there
  is no operation that can cancel out the effect of taking a maximum.
\item If we only need to find the value of combining a \emph{single}
  range $A[i \dots j]$, then ignore everything in this section and
  simply iterate through the interval, combining all the values in
  $O(n)$ time.
\item More typically, we need to do many queries, and $O(n)$ per query
  is not fast enough.  The idea is to preprocess the array into a data
  structure which allows us to answer queries more quickly, \ie in
  $O(1)$ or $O(\lg n)$.
\item Sometimes we also need to be able to \emph{update} the array in
  between queries; in this case we need a more sophisticated query
  data structure that can be quickly updated.
\end{itemize}

Each of the below subsections outlines one approach to solving this
problem; for quick reference, each subsection title says whether an
inverse operation is required, how fast queries are, and whether the
technique can handle updates.

\subsection{Prefix scan (inverse required; $O(1)$ queries; no updates)}

In a situation where we have an inverse operation and we do not need
to update the array, there is a very simple solution.  First, make a
\emph{prefix scan array} $P[0 \dots n]$ such that $P[i]$ stores the
value that results from combining $A[1 \dots i]$.  ($P[0]$ stores the
unique ``identity'' value $a \ominus a$, \eg zero if the combining
operation is sum.)  $P$ can be computed in linear time by scanning
from left to right; each $P[i] = P[i-1] \oplus A[i]$.  Now the value
of $A[i \dots j]$ can be computed in $O(1)$ time as
$P[j] \ominus P[i-1]$. That is, $P[j]$ gives us the value of
$A[1] \oplus \dots \oplus A[j]$, and then we cancel
$P[i-1] = A[1] \oplus \dots \oplus A[i-1]$ to leave just
$A[i] \oplus \dots \oplus A[j]$ as desired.

Note that having $P[0]$ store the identity value is not strictly
necessary, but it removes the need for a special case.  If $A$ is
already $0$-indexed instead of $1$-indexed, then it's probably easier
to just put in a special case for looking up the value of $A[0 \dots
j]$ as $P[j]$, without the need for an inverse operation.

For example, suppose we are given an array of $10^5$ integers, along
with $10^5$ pairs $(i,j)$ for which we must output the sum of
$A[i \dots j]$.  Simply adding up the values in each range would be
too slow. We could solve this with the following code:

\code{range/PrefixSum.java}

More commonly, a prefix scan is a necessary first step in a more
complex solution. \kattis{divisible, dvoniz, srednji, subseqhard}

\subsection{Kadane's Algorithm}

As an aside, suppose we want to find the subsequence $A[i\dots j]$
with the \emph{biggest} sum.  A brute-force approach is $O(n^3)$:
iterate through all $(i,j)$ pairs and find the sum of each
subsequence.  Using the prefix scan approach, we can cut this down to
$O(n^2)$, since we can compute the sums of the $O(n^2)$ possible
subsequences in $O(1)$ time each.  However, there is an even better
$O(n)$ algorithm which is worth knowing, known as \emph{Kadane's
  Algorithm}.

The basic idea is simple: scan through the array, keeping a running
sum in an accumulator, and also keeping track of the biggest total
seen.  Whenever the running sum drops below zero, reset it to zero.
Below is a sample solution to \inlinekattis{commercials}.  Note that
subtracting \texttt{P} from each input is specific to the problem, but
the rest is purely Kadane's Algorithm.

\code{range/Commercials.java}

\subsection{2D prefix scan}

\todo{make pictures}

It is possible to extend the prefix scan idea to two dimensions.
Given a 2D array $A$, we create a parallel 2D array $P$ such that
$P[i][j]$ is the result of combining all the entries of $A$ in the
rectangle from the upper-left corner to $(i,j)$ inclusive.  The
simplest way to do this is to compute \[ P[i][j] = A[i][j] + P[i-1][j]
  + P[i][j-1] - P[i-1][j-1] \] Including $P[i-1][j]$ and $P[i][j-1]$
double counts all the entries in the rectangle from the upper left to
$(i-1,j-1)$ so we have to subtract them.

Given $P$, to compute the combination of the elements in some
rectangle from $(a,b)$ to $(c,d)$, we can compute \[ P[c][d] -
  P[a-1][d] - P[c][b-1] + P[a-1][b-1] \]

\inlinekattis{prozor} can be solved by brute force, but it's a nice
exercise to solve it using the above approach.

\subsection{Doubling windows (no inverse; $O(1)$ queries; no updates)}

\todo{Include link to discussion in CP3}

\subsection{Fenwick trees (inverse required; $O(\lg n)$ queries;
  $O(\lg n)$ updates)}

\kattis{fenwick, supercomputer, turbo, moviecollection, dailydivision}

We can use a \emph{Fenwick tree} to query the range $A[i..j]$ (\ie get
the combination of all the values in the range $A[i] \dots A[j]$
according to the combining operation $\oplus$) in $O(\lg n)$ time.  We
can also dynamically update any entry in the array in $O(\lg n)$ time.
If dynamic updates are required and we have an invertible combining
operation, a Fenwick tree should definitely be the first choice
because the code is quite short. (Segment
trees~\link{sec:segment-trees} can also handle dynamic updates, and
work for any combining operation, even with no inverse, but the
required code is a bit longer.)

The code shown here stores \texttt{int} values and uses addition as
the combining operation, so range queries return the \emph{sum} of all
values in the range; but it can be easily modified for any other type
of values and any other invertible combining operation: change the
type of the array, change the \texttt{+} operation in the
\texttt{prefix} and \texttt{add} methods, change the subtraction
in the \texttt{range} method, and change the assignment \texttt{s = 0}
in \texttt{prefix} to the identity element instead of zero.

\begin{warning}
  Note that this \texttt{FenwickTree} code assumes the
  underlying array is $1$-indexed!
\end{warning}

\code{range/FenwickTree.java}

\begin{itemize}
\item The constructor creates a \texttt{FenwickTree} over an array of
  all zeros.
\item To create a \texttt{FenwickTree} over a given $1$-indexed array
  $A$, simply create a default tree and then loop through the array,
  calling \texttt{ft.add(i, A[i])} for each \texttt{i}.  This takes
  $O(n \lg n)$.
\item \texttt{ft.add(i, delta)} can be used to update the value at a
  particular index by adding \texttt{delta} to it.
\item If you want to simply replace the value at index $i$ instead of
  adding something to it, you could use \texttt{ft.add(i, newValue - ft.range(i,i))}.
\item \texttt{ft.range(i,j)} returns the sum $A[i] + \dots + A[j]$.
\end{itemize}

\todo{Discuss CP3 presentation of Fenwick trees; explain how Fenwick
  trees work}

\subsection{Segment trees (no inverse required; $O(\lg n)$ queries;
  $O(\lg n)$ updates)} \label{sec:segment-trees}

\todo{Segment trees.}

\chapter{Advanced topics} \label{chap:advanced}

This is a list of advanced topics that may eventually be included.

\begin{itemize}
\item Chinese Remainder Theorem \kattis{heliocentric, generalchineseremainder}
\item Exact Set Cover with Algorithm X/dancing links (\inlinekattis{programmingteamselection})
\item Matrix powers
  \kattis{diceandladders,driving,linearrecurrence,mortgage,overlappingmaps,squawk,timing}
\item Min cost max flow
\item Max flow with minimum and maximum capacities
\item Discrete logarithms with baby step/giant step
  (\inlinekattis{discretelogging})
\item Faster primality testing with Miller-Rabin (\eg testing with $a
  = 2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41$ makes it
  deterministic).
\item Divide \& conquer algorithm for counting inversions.
  \kattis{excursion, froshweek}
\item 2-SAT
\item LCA queries: Tarjan's OLCA; via RMQ; binary lifting (\inlinekattis{tourists})

\end{itemize}

\chapter{Resources} \label{chap:resources}

\todo{methodstosolve}
\todo{UVa}
\todo{CP3}
\todo{Geeksforgeeks, topcoder, codeforces}
\todo{cp-algorithms.com}

\end{document}
